{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\metho\\.medmnist\\tissuemnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\metho\\.medmnist\\tissuemnist.npz\n",
      "Epoch 1 - Loss: 1.3321, Accuracy: 50.16%\n",
      "Validation Accuracy: 56.57%\n",
      "Saved improved model\n",
      "Epoch 2 - Loss: 1.1578, Accuracy: 57.17%\n",
      "Validation Accuracy: 58.65%\n",
      "Saved improved model\n",
      "Epoch 3 - Loss: 1.1001, Accuracy: 59.55%\n",
      "Validation Accuracy: 60.77%\n",
      "Saved improved model\n",
      "Epoch 4 - Loss: 1.0637, Accuracy: 60.88%\n",
      "Validation Accuracy: 62.34%\n",
      "Saved improved model\n",
      "Epoch 5 - Loss: 1.0346, Accuracy: 62.06%\n",
      "Validation Accuracy: 62.81%\n",
      "Saved improved model\n",
      "Epoch 6 - Loss: 1.0155, Accuracy: 62.67%\n",
      "Validation Accuracy: 62.38%\n",
      "Epoch 7 - Loss: 0.9970, Accuracy: 63.40%\n",
      "Validation Accuracy: 62.12%\n",
      "Epoch 8 - Loss: 0.9828, Accuracy: 63.88%\n",
      "Validation Accuracy: 63.37%\n",
      "Saved improved model\n",
      "Epoch 9 - Loss: 0.9687, Accuracy: 64.38%\n",
      "Validation Accuracy: 63.06%\n",
      "Epoch 10 - Loss: 0.9591, Accuracy: 64.85%\n",
      "Validation Accuracy: 62.23%\n",
      "Epoch 11 - Loss: 0.9440, Accuracy: 65.32%\n",
      "Validation Accuracy: 63.26%\n",
      "Epoch 12 - Loss: 0.9342, Accuracy: 65.56%\n",
      "Validation Accuracy: 61.84%\n",
      "Epoch 13 - Loss: 0.9237, Accuracy: 65.85%\n",
      "Validation Accuracy: 63.57%\n",
      "Saved improved model\n",
      "Epoch 14 - Loss: 0.9099, Accuracy: 66.27%\n",
      "Validation Accuracy: 62.73%\n",
      "Epoch 15 - Loss: 0.9032, Accuracy: 66.61%\n",
      "Validation Accuracy: 63.35%\n",
      "Epoch 16 - Loss: 0.8951, Accuracy: 66.82%\n",
      "Validation Accuracy: 63.03%\n",
      "Epoch 17 - Loss: 0.8868, Accuracy: 67.08%\n",
      "Validation Accuracy: 61.57%\n",
      "Epoch 18 - Loss: 0.8779, Accuracy: 67.40%\n",
      "Validation Accuracy: 63.30%\n",
      "Epoch 19 - Loss: 0.8714, Accuracy: 67.59%\n",
      "Validation Accuracy: 63.04%\n",
      "Epoch 20 - Loss: 0.8620, Accuracy: 67.99%\n",
      "Validation Accuracy: 62.71%\n"
     ]
    }
   ],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "from medmnist.dataset import TissueMNIST\n",
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_data():\n",
    "    data_transform = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "\n",
    "    train_dataset = TissueMNIST(\n",
    "        split='train',\n",
    "        transform=data_transform,\n",
    "        download=True\n",
    "    )\n",
    "    val_dataset = TissueMNIST(\n",
    "        split='val',\n",
    "        transform=data_transform,\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    n_classes = len(train_dataset.info['label'])\n",
    "\n",
    "    return train_loader, val_loader, n_classes\n",
    "\n",
    "class EnhancedCNN(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(n_channels, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, n_classes, device, save_path):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    num_epochs = 20\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.squeeze(1).long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1} - Loss: {running_loss/len(train_loader):.4f}, '\n",
    "              f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "        val_accuracy = evaluate(model, val_loader, device)\n",
    "        print(f'Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), f\"{save_path}/best_model.pth\")\n",
    "            print(\"Saved improved model\")\n",
    "\n",
    "def evaluate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.squeeze(1).long()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "def main():\n",
    "    train_loader, val_loader, n_classes = load_data()\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = EnhancedCNN(n_channels=1, n_classes=n_classes).to(device)\n",
    "    \n",
    "    save_path = \".\"\n",
    "    train_model(model, train_loader, val_loader, n_classes, device, save_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\metho\\.medmnist\\tissuemnist.npz\n",
      "Test Accuracy: 63.48%\n"
     ]
    }
   ],
   "source": [
    "def load_test_data():\n",
    "    \"\"\"加载测试数据集\"\"\"\n",
    "    data_transform = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "\n",
    "    # 假设使用验证集作为测试集\n",
    "    test_dataset = TissueMNIST(\n",
    "        split='test',\n",
    "        transform=data_transform,\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "    return test_loader\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    \"\"\"测试模型的性能\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.squeeze(1).long()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_classes = 8  # 假设有8个类别，根据你的实际情况修改\n",
    "    model = EnhancedCNN(n_channels=1, n_classes=n_classes).to(device)\n",
    "\n",
    "    # 加载模型权重\n",
    "    model_path = './best_model.pth'  # 确保路径正确\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # 加载测试数据\n",
    "    test_loader = load_test_data()\n",
    "\n",
    "    # 测试模型\n",
    "    test_model(model, test_loader, device)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
