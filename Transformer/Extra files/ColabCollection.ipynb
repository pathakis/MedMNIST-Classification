{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp6z5oJtbOi9"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5rjcDJiObOjB"
      },
      "outputs": [],
      "source": [
        "#%pip install medmnist\n",
        "#%pip install einops\n",
        "#%pip install torcheval\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision.transforms import Resize, ToTensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "from torch import nn\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import torch.optim as optim\n",
        "\n",
        "from medmnist import PneumoniaMNIST, RetinaMNIST, ChestMNIST\n",
        "import time\n",
        "\n",
        "from einops import rearrange\n",
        "from einops import repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "from medmnist import PneumoniaMNIST\n",
        "from medmnist import PneumoniaMNIST, RetinaMNIST, ChestMNIST\n",
        "from random import random\n",
        "from torch import Tensor\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torcheval.metrics import MulticlassAccuracy\n",
        "from torchvision.transforms import Resize, ToTensor\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torcheval.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuVJfbuPbOjC"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o4F2-hnubOjD"
      },
      "outputs": [],
      "source": [
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, image):\n",
        "        for t in self.transforms:\n",
        "            image = t(image)\n",
        "        return image\n",
        "\n",
        "class MedMNISTDataset(Dataset):\n",
        "    def __init__(self, dataset, transform=None, dataset_type='train', img_size=224, nSamples=0,augment_data=False, balance_classes=False):\n",
        "        self.dataset = dataset(split=dataset_type, download=True, size=img_size, as_rgb=True)\n",
        "        self.transform = transform\n",
        "        self.augment_data = augment_data\n",
        "        self.increaseSize = nSamples\n",
        "        if augment_data == False:\n",
        "            self.Transform()\n",
        "\n",
        "        if balance_classes:\n",
        "            self.BalanceClasses(nSamples, verbose=True)\n",
        "\n",
        "    def Transform(self):\n",
        "        tempDataset = []\n",
        "        for idx, (image, label) in enumerate(self.dataset):\n",
        "            if self.transform is not None:\n",
        "                image = self.transform(image)\n",
        "            tempDataset.append((image, label))\n",
        "        self.dataset = tempDataset\n",
        "\n",
        "    def BalanceClasses(self, increaseSize=0, verbose=False):\n",
        "        '''\n",
        "        Balance the classes in the dataset by resampling the minority classes. For the best efftect\n",
        "        augmentation should be enabled. Otherwise the same image will be duplicated within the dataset.\n",
        "        '''\n",
        "        print('Balancing classes...')\n",
        "\n",
        "        # Get the number of samples in each class\n",
        "        num_samples = {}\n",
        "        for _, label in self.dataset:\n",
        "            label = label[0]\n",
        "            #print(f'Label: {label}', type(label))\n",
        "            if label not in num_samples:\n",
        "                num_samples[label] = 0\n",
        "            num_samples[label] += 1\n",
        "        self.num_classes = len(num_samples)\n",
        "        if verbose:\n",
        "            print(f'Before balancing: {num_samples} | Num classes: {self.num_classes}')\n",
        "\n",
        "        # Find the class with the most samples\n",
        "        if increaseSize > 0:\n",
        "            if int(increaseSize / len(num_samples)) < max(num_samples.values()):\n",
        "                max_samples = max(num_samples.values())\n",
        "            else:\n",
        "                max_samples = int(increaseSize / len(num_samples))\n",
        "                print(len(num_samples), increaseSize, increaseSize / len(num_samples), int(increaseSize / len(num_samples)))\n",
        "                print(f'Increasing size to {max_samples} samples per class.')\n",
        "        else:\n",
        "            max_samples = max(num_samples.values())\n",
        "\n",
        "        # Create a balanced dataset\n",
        "        balanced_dataset = []\n",
        "        for image, label in self.dataset:\n",
        "            balanced_dataset.append((image, label))\n",
        "\n",
        "        # Resample minority classes\n",
        "        for label, count in num_samples.items():\n",
        "            if count < max_samples:\n",
        "                # Number of samples to add\n",
        "                num_to_add = max_samples - count\n",
        "\n",
        "                # Get indices of samples in the minority class\n",
        "                class_indices = [idx for idx, (_, l) in enumerate(self.dataset) if l == label]\n",
        "\n",
        "                # Select indices to resample\n",
        "                selected_indices = np.random.choice(class_indices, num_to_add, replace=True)\n",
        "\n",
        "                for idx in selected_indices:\n",
        "                    image, label = self.dataset[idx]\n",
        "                    balanced_dataset.append((image, label))\n",
        "        self.dataset = balanced_dataset\n",
        "\n",
        "        # Control the balance\n",
        "        if verbose:\n",
        "            num_samples = {}\n",
        "            for _, label in self.dataset:\n",
        "                label = label[0]\n",
        "                if label not in num_samples:\n",
        "                    num_samples[label] = 0\n",
        "                num_samples[label] += 1\n",
        "            print('After balancing: ', num_samples)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Get an item from the dataset, if augmention is enabled, augment the data.\n",
        "        '''\n",
        "        image, label = self.dataset[idx]\n",
        "        if self.augment_data and type(image) != torch.Tensor:\n",
        "            image = np.asarray(image)\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "            if type(image) != torch.Tensor:\n",
        "                image = ToTensor()(image)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-I1SvYcbOjE"
      },
      "source": [
        "# ViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n81DCkRQbOjE"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads, dropout):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.att = torch.nn.MultiheadAttention(embed_dim=dim, num_heads=heads, dropout=dropout)\n",
        "        self.q = nn.Linear(dim, dim)\n",
        "        self.k = nn.Linear(dim, dim)\n",
        "        self.v = nn.Linear(dim, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        q = self.q(x)\n",
        "        k = self.k(x)\n",
        "        v = self.v(x)\n",
        "        attn_output, attn_output_weights = self.att(x,x,x)\n",
        "        return attn_output\n",
        "\n",
        "\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels=3,\n",
        "                 patch_size=8,\n",
        "                 embedding_size=224\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.projection = nn.Sequential(\n",
        "            Rearrange('b c (h s1) (w s2) -> b (h w) (s1 s2 c)', s1=patch_size, s2=patch_size),\n",
        "            nn.Linear(patch_size * patch_size * in_channels, embedding_size)\n",
        "            )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.projection(x)\n",
        "\n",
        "\n",
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, image):\n",
        "        for t in self.transforms:\n",
        "            if hasattr(t, \"is_albumentation\"):\n",
        "                # If the transform is an Albumentations transform, apply it\n",
        "                image = t(image=image)[\"image\"]\n",
        "            else:\n",
        "                # If it's a torchvision transform, apply it\n",
        "                image = t(image)\n",
        "            #image = t(image=image)\n",
        "        return image\n",
        "\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Sequential):\n",
        "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
        "        super().__init__(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "\n",
        "class ResidualAdd(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "    def forward(self, x, **kwargs):\n",
        "        res = x\n",
        "        x = self.fn(x, **kwargs)\n",
        "        x += res\n",
        "        return x\n",
        "\n",
        "\n",
        "class ViT(nn.Module):\n",
        "    def __init__(self, channels=3,\n",
        "                 img_size=224,\n",
        "                 patch_size=4,\n",
        "                 embedding_dim=32,\n",
        "                 layers=6,\n",
        "                 out_dim=37,\n",
        "                 dropout=0.1,\n",
        "                 heads=2\n",
        "                 ):\n",
        "        super(ViT, self).__init__()\n",
        "\n",
        "        # Attributes\n",
        "        self.channels = channels # Number of channels in the input image (Grayscale = 1, RGB = 3)\n",
        "        self.height = img_size # Height of the input image\n",
        "        self.width = img_size # Width of the input image\n",
        "        self.patch_size = patch_size # Size of the patches to be extracted from the input image (Think of mini images within image or kenel snapshots)\n",
        "        self.n_layers = layers\n",
        "\n",
        "        # Patching\n",
        "        self.patch_embedding = PatchEmbedding(in_channels=channels,\n",
        "                                              patch_size=patch_size,\n",
        "                                              embedding_size=embedding_dim\n",
        "                                              )\n",
        "\n",
        "        # Learnable parameters\n",
        "        num_patches = (img_size // patch_size) ** 2\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, embedding_dim))\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, embedding_dim))\n",
        "\n",
        "        # Transformer encoder\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(layers):\n",
        "            transformer_block = nn.Sequential(\n",
        "                ResidualAdd(PreNorm(embedding_dim, Attention(embedding_dim, heads, dropout))),\n",
        "                ResidualAdd(PreNorm(embedding_dim, FeedForward(embedding_dim, embedding_dim, dropout)))\n",
        "            )\n",
        "            self.layers.append(transformer_block)\n",
        "\n",
        "        # Classification head\n",
        "        self.head = nn.Sequential(nn.LayerNorm(embedding_dim), nn.Linear(embedding_dim, out_dim))\n",
        "\n",
        "    def forward(self, img):\n",
        "        # Get patch embedding vectors\n",
        "        img = self.patch_embedding(img)\n",
        "        b, n, _ = img.shape\n",
        "\n",
        "        # Add positional embedding to the patches\n",
        "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b=b)\n",
        "        img = torch.cat([cls_tokens, img], dim=1)\n",
        "        img += self.pos_embedding[:, :(n + 1)]\n",
        "\n",
        "        # Transformer layers\n",
        "        for layer in self.layers:\n",
        "            img = layer(img)\n",
        "\n",
        "        # Classification head\n",
        "        assigned_class = self.head(img[:, 0, :])\n",
        "        return assigned_class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ssjh4dgbOjF"
      },
      "source": [
        "# Optimiser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sfgROW1kbOjF"
      },
      "outputs": [],
      "source": [
        "class ViT_Optimiser:\n",
        "    def __init__(self, dataset, img_size=224, augment_data=False):\n",
        "        self.device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "        print(f' > Using device: {self.device}\\n')\n",
        "        if self.device == \"cpu\":\n",
        "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            print(f' > Using device: {self.device}\\n')\n",
        "            if self.device == \"cpu\":\n",
        "                print(\"WARNING: MPS not available, using CPU instead.\")\n",
        "                if input(\"Continue? (y/n): \") != \"y\":\n",
        "                    exit()\n",
        "\n",
        "        # Parameters\n",
        "        self.img_size = int(img_size)\n",
        "        self.augment_data = augment_data\n",
        "\n",
        "        # Load training and validation data\n",
        "        self.LoadDatasets(dataset)\n",
        "        self.dataset = dataset\n",
        "        self.LoadPerformance()\n",
        "        print(self.modelPerformance)\n",
        "        if str(dataset.__name__) not in self.modelPerformance:\n",
        "            self.modelPerformance[str(dataset.__name__)] = {'Training': {'Accuracy': 0, 'F1': 0}, 'Validation': {'Accuracy': 0, 'F1': 0}, 'Model': 'ViT', 'Loss function': 'CrossEntropyLoss'}\n",
        "            print(self.modelPerformance)\n",
        "            self.SavePerformance()\n",
        "\n",
        "        # Define model\n",
        "        self.model = ViT(out_dim=self.num_classes).to(self.device)\n",
        "        try:\n",
        "            if str(dataset.__name__) in self.modelPerformance:\n",
        "                self.LoadModel(dataset.__name__)\n",
        "        except:\n",
        "            print(\"No model found, training new model...\")\n",
        "\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
        "\n",
        "        self.trainingCriterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        #self.testCriterion = nn.Accuracy()\n",
        "\n",
        "    def LoadDatasets(self, dataset):\n",
        "        if self.augment_data:\n",
        "            print(\"Augmenting data...\")\n",
        "            trainingTransformer = A.Compose([\n",
        "                    A.Rotate(limit=30, p=0.5),              # Rotate the image by up to 30 degrees with a probability of 0.5\n",
        "                    A.RandomScale(scale_limit=0.2, p=0.5),  # Randomly scale the image by up to 20% with a probability of 0.5\n",
        "                    A.RandomBrightnessContrast(p=0.5),      # Randomly adjust brightness and contrast with a probability of 0.5\n",
        "                    A.GaussianBlur(p=0.5),                  # Apply Gaussian blur with a probability of 0.5\n",
        "                    #A.RandomNoise(p=0.5),                   # Add random noise with a probability of 0.5\n",
        "                    A.HorizontalFlip(p=0.5),                # Flip the image horizontally with a probability of 0.5\n",
        "                    A.VerticalFlip(p=0.5),                  # Flip the image vertically with a probability of 0.5\n",
        "                    #A.RandomCrop(height=224, width=224),    # Randomly crop the image to size 224x224\n",
        "                    A.GridDistortion(p=0.5),                # Apply grid distortion with a probability of 0.5\n",
        "                    A.Resize(height=self.img_size, width=self.img_size),   # Resize the image to the desired size\n",
        "                    A.Normalize(),                          # Normalize the image                             # Convert the image to a PyTorch tensor\n",
        "                    ])\n",
        "        else:\n",
        "            trainingTransformer = Compose([\n",
        "                Resize((self.img_size, self.img_size)),\n",
        "                ToTensor()]\n",
        "                )\n",
        "        standardTransformer = Compose([Resize((self.img_size, self.img_size)), ToTensor()])\n",
        "        self.training = MedMNISTDataset(dataset, transform=trainingTransformer, dataset_type='train', img_size=self.img_size, augment_data=self.augment_data, balance_classes=True)\n",
        "        self.train_loader = DataLoader(self.training, batch_size=32, shuffle=True)\n",
        "        self.num_classes = self.training.num_classes\n",
        "\n",
        "        self.validation = MedMNISTDataset(dataset, transform=standardTransformer, dataset_type='val', img_size=self.img_size)\n",
        "        self.validation_loader = DataLoader(self.validation, batch_size=32, shuffle=True)\n",
        "\n",
        "        self.test = MedMNISTDataset(dataset, transform=standardTransformer, dataset_type='test', img_size=self.img_size)\n",
        "        self.test_loader = DataLoader(self.test, batch_size=32, shuffle=True)\n",
        "\n",
        "    def RunOptimiser(self, epochs):\n",
        "        print(f\"Running optimiser for {epochs} epochs on {str(self.dataset.__name__)} dataset...\")\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            epoch_losses = { \"training\": [], \"validation\": []}\n",
        "            self.model.train()\n",
        "            collected_training_output = []\n",
        "            collected_validation_output = []\n",
        "            collected_test_output = []\n",
        "            collected_training_labels = []\n",
        "            collected_validation_labels = []\n",
        "            collected_test_labels = []\n",
        "\n",
        "            # Optimise model on training data\n",
        "            for step, (input, labels) in tqdm(enumerate(self.train_loader), desc=f\"Epoch {epoch+1}\", total=len(self.train_loader)):\n",
        "                input, labels = input.to(self.device), labels.to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                #print(input.shape)\n",
        "                output = self.model(input)\n",
        "                loss = self.trainingCriterion(output, labels.squeeze())\n",
        "                collected_training_output += output.tolist()\n",
        "                collected_training_labels += labels.squeeze().tolist()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                epoch_losses[\"training\"].append(loss.item())\n",
        "\n",
        "            trainingPerformance = self.EvaluatePerformance(collected_training_output, collected_training_labels)\n",
        "\n",
        "            # Run model over validation data\n",
        "            for step, (input, labels) in enumerate(self.validation_loader):\n",
        "                input, labels = input.to(self.device), labels.to(self.device)\n",
        "                output = self.model(input)\n",
        "                collected_validation_output += output.tolist()\n",
        "                collected_validation_labels += labels.squeeze().tolist()\n",
        "                loss = self.trainingCriterion(output, labels.squeeze())\n",
        "                epoch_losses[\"validation\"].append(loss.item())\n",
        "\n",
        "            validationPerformance = self.EvaluatePerformance(collected_validation_output, collected_validation_labels)\n",
        "\n",
        "            print(f'\\nEpoch {epoch+1}/{epochs}\\n')\n",
        "            print(f'   Training set:\\n')\n",
        "            print(f'      - Loss: {np.mean(epoch_losses[\"training\"]):.2f} | Accuracy: {trainingPerformance[\"Accuracy\"]:.2f} | F1: {trainingPerformance[\"F1\"]:.2f}\\n')\n",
        "            print(f'   Validation set:\\n')\n",
        "            print(f'      - Loss: {np.mean(epoch_losses[\"validation\"]):.2f} | Accuracy: {validationPerformance[\"Accuracy\"]:.2f} | F1: {validationPerformance[\"F1\"]:.2f}\\n')\n",
        "\n",
        "            # If model has better performance on validation set than previous runs, save model\n",
        "            if validationPerformance[\"Accuracy\"] > self.modelPerformance[str(self.dataset.__name__)]['Validation']['Accuracy']:\n",
        "                self.modelPerformance[str(self.dataset.__name__)]['Training'] = trainingPerformance\n",
        "                self.modelPerformance[str(self.dataset.__name__)]['Validation'] = validationPerformance\n",
        "                self.SavePerformance()\n",
        "                self.SaveModel(self.dataset.__name__)\n",
        "\n",
        "            #print(f\"\\nEpoch {epoch+1}\\n   - Training loss: {np.mean(epoch_losses['training'])}\\n   - Validation loss: {np.mean(epoch_losses['validation'])}\\n\\n\")\n",
        "\n",
        "        for step, (input, labels) in enumerate(self.test_loader):\n",
        "            input, labels = input.to(self.device), labels.to(self.device)\n",
        "            output = self.model(input)\n",
        "            collected_test_output += output.tolist()\n",
        "            collected_test_labels += labels.squeeze().tolist()\n",
        "            loss = self.trainingCriterion(output, labels.squeeze())\n",
        "\n",
        "        testPerformance = self.EvaluatePerformance(collected_test_output, collected_test_labels)\n",
        "        print(f'   Test set:')\n",
        "        print(f'      - Loss: {loss.item():.2f} | Accuracy: {testPerformance[\"Accuracy\"]:.2f} | F1: {testPerformance[\"F1\"]:.2f}')\n",
        "\n",
        "    def EvaluatePerformance(self, output, labels):\n",
        "        # Make predictions available on CPU\n",
        "        output_np = np.array(output)\n",
        "        labels_np = np.array(labels)\n",
        "        #output_np = output.detach().cpu().numpy()\n",
        "        #labels_np = labels.detach().cpu().numpy()\n",
        "        output_np = np.argmax(output_np, axis=1)\n",
        "\n",
        "        # Calculate performance metrics\n",
        "        accuracy = accuracy_score(labels_np, output_np)                 # Calculate accuracy\n",
        "        f1 = f1_score(labels_np, output_np, average='macro')            # Calculate F1 score\n",
        "        return {'Accuracy': accuracy, 'F1': f1}\n",
        "\n",
        "    def SaveModel(self, filename):\n",
        "        print(\"Saving model...\")\n",
        "        directory = 'Transformer/Models'\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "\n",
        "        filepath = os.path.join(directory, filename + '.pth')\n",
        "\n",
        "        torch.save(self.model.state_dict(), filepath)\n",
        "        print(f\"Model saved to '{filepath}'.\")\n",
        "\n",
        "    def LoadModel(self, filename):\n",
        "        print(\"Loading model...\")\n",
        "        path = 'Transformer/Models/' + filename + '.pth'\n",
        "        self.model.load_state_dict(torch.load(path))\n",
        "        print(f\"Model loaded from '{path}'.\")\n",
        "\n",
        "    def SavePerformance(self):\n",
        "        path = 'Transformer/Models/Performance.pkl'\n",
        "        with open(path, 'wb') as file:\n",
        "            pickle.dump(self.modelPerformance, file)\n",
        "\n",
        "    def LoadPerformance(self):\n",
        "        with open('Transformer/Models/Performance.pkl', 'rb') as file:\n",
        "            self.modelPerformance = pickle.load(file)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fRzGsQ9bOjF"
      },
      "source": [
        "# Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CL1s40TobOjG"
      },
      "outputs": [],
      "source": [
        "def RunViT_Test():\n",
        "    # Test normalisation class / layer\n",
        "    print('\\nTesting normalisation PreNorm class...')\n",
        "    norm = PreNorm(64, Attention(64, 8, 0.1))\n",
        "    print(norm(torch.ones(10, 64, 64)).shape)\n",
        "    print('Normalisation test passed.\\n\\n\\n')\n",
        "\n",
        "    # Test feed forward class\n",
        "    print('Testing feed forward class...')\n",
        "    ff = FeedForward(64, 128)\n",
        "    print(ff(torch.ones(10, 64, 64)).shape)\n",
        "    print('Feed forward test passed.\\n\\n\\n')\n",
        "\n",
        "    # Test residual attention class\n",
        "    print('Testing residual attention class...')\n",
        "    residual_att = ResidualAdd(Attention(64, 8, 0.))\n",
        "    print(residual_att(torch.ones(10, 64, 64)).shape)\n",
        "    print('Residual attention test passed.\\n\\n\\n')\n",
        "\n",
        "    # Test patch embedding\n",
        "    print('Testing patch embedding...')\n",
        "    to_tensor = [Resize((224, 224)), ToTensor()]\n",
        "    dataset = PneumoniaMNIST(split='train', download=True, size=224, as_rgb=True,transform=Compose(to_tensor))\n",
        "    sample_datapoint = torch.unsqueeze(dataset[0][0], 0)\n",
        "    print(\"Initial shape: \", sample_datapoint.shape)\n",
        "    print(sample_datapoint)\n",
        "    embedding = PatchEmbedding()(sample_datapoint)\n",
        "    print(\"Patches shape: \", embedding.shape)\n",
        "    print('Patch embedding test passed.\\n\\n\\n')\n",
        "\n",
        "    # Test ViT model\n",
        "    print('Testing ViT model...')\n",
        "    model = ViT(out_dim=5)\n",
        "    print(model)\n",
        "    print(model(torch.rand(1, 3, 224, 224)))\n",
        "    print('ViT model test passed.')\n",
        "\n",
        "def GPUAccessTest():\n",
        "    '''\n",
        "    Check access to GPU devices for TensorFlow and PyTorch, might only work on macOS.\n",
        "    '''\n",
        "    # Check for TensorFlow GPU access\n",
        "    print(f\"\\nTensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
        "    # See TensorFlow version\n",
        "    print(f\" > TensorFlow version: {tf.__version__}\")\n",
        "    print(f' > Pytorch version', torch.__version__)\n",
        "    print(f' > Is MPS built? {torch.backends.mps.is_built()}')\n",
        "    print(f' > Is MPS available? {torch.backends.mps.is_available()}')\n",
        "\n",
        "    device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "    print(f' > Using device: {device}\\n')\n",
        "\n",
        "    x = torch.rand(size=(3,4)).to(device)\n",
        "    print(f\" > Tensor: {x}\")\n",
        "\n",
        "def RunOptimisationTest(dataset, augment,balance_classes, epochs=2):\n",
        "    '''\n",
        "    Test the ViT optimiser class.\n",
        "    '''\n",
        "    optimiser = ViT_Optimiser(dataset, augment_data=augment, img_size=224)\n",
        "    optimiser.RunOptimiser(epochs)\n",
        "\n",
        "def SaveModelTest():\n",
        "    '''\n",
        "    Test saving and loading a model.\n",
        "    '''\n",
        "    trainer = ViT_Optimiser(RetinaMNIST, augment_data=True)\n",
        "    trainer.RunOptimiser(2)\n",
        "    model = trainer.model\n",
        "    device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "    torch.save(model.state_dict(), 'Transformer/Models/RetinaModel.pth')\n",
        "    print(f'Model saved on device {device}. At location: Transformers/Models/RetinaModel.pth.')\n",
        "\n",
        "def LoadModelTest():\n",
        "    '''\n",
        "    Test loading a model.\n",
        "    '''\n",
        "    device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "    model = ViT().to(device)\n",
        "    model.load_state_dict(torch.load('Transformer/Models/RetinaModel.pth'))\n",
        "    model\n",
        "    print('Model loaded.')\n",
        "    trainer = ViT_Optimiser(RetinaMNIST, 2)\n",
        "    trainer.model = model\n",
        "    trainer.RunOptimiser(2)\n",
        "    print('Model loaded and tested.')\n",
        "\n",
        "def IntegratedSaveLoadTest(mode='save'):\n",
        "    '''\n",
        "    Test saving and loading a model using the integrated functions.\n",
        "    '''\n",
        "    if mode == 'save':\n",
        "        trainer = ViT_Optimiser(RetinaMNIST, augment_data=False, img_size=224)\n",
        "        trainer.RunOptimiser(2)\n",
        "        trainer.SaveModel(trainer.dataset.__name__)\n",
        "        print('Model saved succesfully.')\n",
        "    elif mode == 'Load':\n",
        "        trainer = ViT_Optimiser(RetinaMNIST, augment_data=True)\n",
        "        trainer.LoadModel(trainer.dataset.__name__)\n",
        "        trainer.RunOptimiser(2)\n",
        "        print('Model loaded succesfully.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "kOfQTN86dcx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RunOptimisationTest(PneumoniaMNIST, True, True, 150)"
      ],
      "metadata": {
        "id": "FDSgHN1Ycopk"
      },
      "execution_count": 1,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}